### YamlMime:TSType
name: Face
uid: '@azure/cognitiveservices-face.Face'
package: '@azure/cognitiveservices-face'
summary: Class representing a Face.
fullName: Face
remarks: ''
isPreview: false
isDeprecated: false
type: class
constructors:
  - name: Face(FaceClientContext)
    uid: '@azure/cognitiveservices-face.Face.constructor'
    package: '@azure/cognitiveservices-face'
    summary: Create a Face.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'new Face(client: FaceClientContext)'
      parameters:
        - id: client
          type: <xref uid="@azure/cognitiveservices-face.FaceClientContext" />
          description: |
            Reference to the service client.
methods:
  - name: >-
      detectWithStream(msRest.HttpRequestBody,
      FaceDetectWithStreamOptionalParams, ServiceCallback<DetectedFace[]>)
    uid: '@azure/cognitiveservices-face.Face.detectWithStream_2'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function detectWithStream(image: msRest.HttpRequestBody, options:
        FaceDetectWithStreamOptionalParams, callback:
        ServiceCallback<DetectedFace[]>)
      parameters:
        - id: image
          type: <xref uid="msRest.HttpRequestBody" />
          description: An image stream.
        - id: options
          type: >-
            <xref
            uid="@azure/cognitiveservices-face.FaceDetectWithStreamOptionalParams"
            />
          description: The optional parameters
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.DetectedFace" />[]&gt;
          description: |
            The callback
  - name: >-
      detectWithStream(msRest.HttpRequestBody,
      Models.FaceDetectWithStreamOptionalParams)
    uid: '@azure/cognitiveservices-face.Face.detectWithStream'
    package: '@azure/cognitiveservices-face'
    summary: >-
      Detect human faces in an image, return face rectangles, and optionally
      with faceIds, landmarks,

      and attributes.<br />

      * No image will be stored. Only the extracted face feature will be stored
      on server. The faceId

      is an identifier of the face feature and will be used in [Face -

      Identify](https://docs.microsoft.com/rest/api/faceapi/face/identify),
      [Face -

      Verify](https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface),
      and [Face - Find

      Similar](https://docs.microsoft.com/rest/api/faceapi/face/findsimilar).
      The stored face

      feature(s) will expire and be deleted at the time specified by
      faceIdTimeToLive after the

      original detection call.

      * Optional parameters include faceId, landmarks, and attributes.
      Attributes include age, gender,

      headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion,
      accessories, blur,

      exposure, noise, and mask. Some of the results returned for specific
      attributes may not be

      highly accurate.

      * JPEG, PNG, GIF (the first frame), and BMP format are supported. The
      allowed image file size is

      from 1KB to 6MB.

      * Up to 100 faces can be returned for an image. Faces are ranked by face
      rectangle size from

      large to small.

      * For optimal results when querying [Face -

      Identify](https://docs.microsoft.com/rest/api/faceapi/face/identify),
      [Face -

      Verify](https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface),
      and [Face - Find

      Similar](https://docs.microsoft.com/rest/api/faceapi/face/findsimilar)
      ('returnFaceId' is true),

      please use faces that are: frontal, clear, and with a minimum size of
      200x200 pixels (100 pixels

      between eyes).

      * The minimum detectable face size is 36x36 pixels in an image no larger
      than 1920x1080 pixels.

      Images with dimensions higher than 1920x1080 pixels will need a
      proportionally larger minimum

      face size.

      * Different 'detectionModel' values can be provided. To use and compare
      different detection

      models, please refer to [How to specify a detection

      model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)

      * Different 'recognitionModel' values are provided. If follow-up
      operations like Verify,

      Identify, Find Similar are needed, please specify the recognition model
      with 'recognitionModel'

      parameter. The default value for 'recognitionModel' is 'recognition_01',
      if latest model needed,

      please explicitly specify the model you need in this parameter. Once
      specified, the detected

      faceIds will be associated with the specified recognition model. More
      details, please refer to

      [Specify a recognition

      model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model).
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function detectWithStream(image: msRest.HttpRequestBody, options?:
        Models.FaceDetectWithStreamOptionalParams)
      parameters:
        - id: image
          type: <xref uid="msRest.HttpRequestBody" />
          description: An image stream.
        - id: options
          type: <xref uid="Models.FaceDetectWithStreamOptionalParams" />
          description: ''
      return:
        type: Promise&lt;<xref uid="Models.FaceDetectWithStreamResponse" />&gt;
        description: Promise<Models.FaceDetectWithStreamResponse>
  - name: 'detectWithStream(msRest.HttpRequestBody, ServiceCallback<DetectedFace[]>)'
    uid: '@azure/cognitiveservices-face.Face.detectWithStream_1'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function detectWithStream(image: msRest.HttpRequestBody, callback:
        ServiceCallback<DetectedFace[]>)
      parameters:
        - id: image
          type: <xref uid="msRest.HttpRequestBody" />
          description: An image stream.
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.DetectedFace" />[]&gt;
          description: |
            The callback
  - name: >-
      detectWithUrl(string, FaceDetectWithUrlOptionalParams,
      ServiceCallback<DetectedFace[]>)
    uid: '@azure/cognitiveservices-face.Face.detectWithUrl_2'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function detectWithUrl(url: string, options:
        FaceDetectWithUrlOptionalParams, callback:
        ServiceCallback<DetectedFace[]>)
      parameters:
        - id: url
          type: string
          description: Publicly reachable URL of an image
        - id: options
          type: >-
            <xref
            uid="@azure/cognitiveservices-face.FaceDetectWithUrlOptionalParams"
            />
          description: The optional parameters
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.DetectedFace" />[]&gt;
          description: |
            The callback
  - name: 'detectWithUrl(string, Models.FaceDetectWithUrlOptionalParams)'
    uid: '@azure/cognitiveservices-face.Face.detectWithUrl'
    package: '@azure/cognitiveservices-face'
    summary: >-
      Detect human faces in an image, return face rectangles, and optionally
      with faceIds, landmarks,

      and attributes.<br />

      * No image will be stored. Only the extracted face feature will be stored
      on server. The faceId

      is an identifier of the face feature and will be used in [Face -

      Identify](https://docs.microsoft.com/rest/api/faceapi/face/identify),
      [Face -

      Verify](https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface),
      and [Face - Find

      Similar](https://docs.microsoft.com/rest/api/faceapi/face/findsimilar).
      The stored face

      feature(s) will expire and be deleted at the time specified by
      faceIdTimeToLive after the

      original detection call.

      * Optional parameters include faceId, landmarks, and attributes.
      Attributes include age, gender,

      headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion,
      accessories, blur,

      exposure, noise, and mask. Some of the results returned for specific
      attributes may not be

      highly accurate.

      * JPEG, PNG, GIF (the first frame), and BMP format are supported. The
      allowed image file size is

      from 1KB to 6MB.

      * Up to 100 faces can be returned for an image. Faces are ranked by face
      rectangle size from

      large to small.

      * For optimal results when querying [Face -

      Identify](https://docs.microsoft.com/rest/api/faceapi/face/identify),
      [Face -

      Verify](https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface),
      and [Face - Find

      Similar](https://docs.microsoft.com/rest/api/faceapi/face/findsimilar)
      ('returnFaceId' is true),

      please use faces that are: frontal, clear, and with a minimum size of
      200x200 pixels (100 pixels

      between eyes).

      * The minimum detectable face size is 36x36 pixels in an image no larger
      than 1920x1080 pixels.

      Images with dimensions higher than 1920x1080 pixels will need a
      proportionally larger minimum

      face size.

      * Different 'detectionModel' values can be provided. To use and compare
      different detection

      models, please refer to [How to specify a detection

      model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model).

      * Different 'recognitionModel' values are provided. If follow-up
      operations like Verify,

      Identify, Find Similar are needed, please specify the recognition model
      with 'recognitionModel'

      parameter. The default value for 'recognitionModel' is 'recognition_01',
      if latest model needed,

      please explicitly specify the model you need in this parameter. Once
      specified, the detected

      faceIds will be associated with the specified recognition model. More
      details, please refer to

      [Specify a recognition

      model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model).
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function detectWithUrl(url: string, options?:
        Models.FaceDetectWithUrlOptionalParams)
      parameters:
        - id: url
          type: string
          description: Publicly reachable URL of an image
        - id: options
          type: <xref uid="Models.FaceDetectWithUrlOptionalParams" />
          description: ''
      return:
        type: Promise&lt;<xref uid="Models.FaceDetectWithUrlResponse" />&gt;
        description: Promise<Models.FaceDetectWithUrlResponse>
  - name: 'detectWithUrl(string, ServiceCallback<DetectedFace[]>)'
    uid: '@azure/cognitiveservices-face.Face.detectWithUrl_1'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function detectWithUrl(url: string, callback:
        ServiceCallback<DetectedFace[]>)
      parameters:
        - id: url
          type: string
          description: Publicly reachable URL of an image
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.DetectedFace" />[]&gt;
          description: |
            The callback
  - name: >-
      findSimilar(string, FaceFindSimilarOptionalParams,
      ServiceCallback<SimilarFace[]>)
    uid: '@azure/cognitiveservices-face.Face.findSimilar_2'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function findSimilar(faceId: string, options:
        FaceFindSimilarOptionalParams, callback: ServiceCallback<SimilarFace[]>)
      parameters:
        - id: faceId
          type: string
          description: >-
            FaceId of the query face. User needs to call Face - Detect first to
            get a valid

            faceId. Note that this faceId is not persisted and will expire at
            the time specified by

            faceIdTimeToLive after the detection call
        - id: options
          type: >-
            <xref
            uid="@azure/cognitiveservices-face.FaceFindSimilarOptionalParams" />
          description: The optional parameters
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.SimilarFace" />[]&gt;
          description: |
            The callback
  - name: 'findSimilar(string, Models.FaceFindSimilarOptionalParams)'
    uid: '@azure/cognitiveservices-face.Face.findSimilar'
    package: '@azure/cognitiveservices-face'
    summary: >-
      Given query face's faceId, to search the similar-looking faces from a
      faceId array, a face list

      or a large face list. faceId array contains the faces created by [Face -
      Detect With

      Url](https://docs.microsoft.com/rest/api/faceapi/face/detectwithurl) or
      [Face - Detect With

      Stream](https://docs.microsoft.com/rest/api/faceapi/face/detectwithstream),
      which will expire at

      the time specified by faceIdTimeToLive after creation. A "faceListId" is
      created by [FaceList -

      Create](https://docs.microsoft.com/rest/api/faceapi/facelist/create)
      containing persistedFaceIds

      that will not expire. And a "largeFaceListId" is created by [LargeFaceList
      -

      Create](https://docs.microsoft.com/rest/api/faceapi/largefacelist/create)
      containing

      persistedFaceIds that will also not expire. Depending on the input the
      returned similar faces

      list contains faceIds or persistedFaceIds ranked by similarity.

      <br/>Find similar has two working modes, "matchPerson" and "matchFace".
      "matchPerson" is the

      default mode that it tries to find faces of the same person as possible by
      using internal

      same-person thresholds. It is useful to find a known person's other
      photos. Note that an empty

      list will be returned if no faces pass the internal thresholds.
      "matchFace" mode ignores

      same-person thresholds and returns ranked similar faces anyway, even the
      similarity is low. It

      can be used in the cases like searching celebrity-looking faces.

      <br/>The 'recognitionModel' associated with the query face's faceId should
      be the same as the

      'recognitionModel' used by the target faceId array, face list or large
      face list.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function findSimilar(faceId: string, options?:
        Models.FaceFindSimilarOptionalParams)
      parameters:
        - id: faceId
          type: string
          description: >-
            FaceId of the query face. User needs to call Face - Detect first to
            get a valid

            faceId. Note that this faceId is not persisted and will expire at
            the time specified by

            faceIdTimeToLive after the detection call
        - id: options
          type: <xref uid="Models.FaceFindSimilarOptionalParams" />
          description: ''
      return:
        type: Promise&lt;<xref uid="Models.FaceFindSimilarResponse" />&gt;
        description: Promise<Models.FaceFindSimilarResponse>
  - name: 'findSimilar(string, ServiceCallback<SimilarFace[]>)'
    uid: '@azure/cognitiveservices-face.Face.findSimilar_1'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function findSimilar(faceId: string, callback:
        ServiceCallback<SimilarFace[]>)
      parameters:
        - id: faceId
          type: string
          description: >-
            FaceId of the query face. User needs to call Face - Detect first to
            get a valid

            faceId. Note that this faceId is not persisted and will expire at
            the time specified by

            faceIdTimeToLive after the detection call
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.SimilarFace" />[]&gt;
          description: |
            The callback
  - name: 'group(string[], msRest.RequestOptionsBase)'
    uid: '@azure/cognitiveservices-face.Face.group'
    package: '@azure/cognitiveservices-face'
    summary: >-
      Divide candidate faces into groups based on face similarity.<br />

      * The output is one or more disjointed face groups and a messyGroup. A
      face group contains faces

      that have similar looking, often of the same person. Face groups are
      ranked by group size, i.e.

      number of faces. Notice that faces belonging to a same person might be
      split into several groups

      in the result.

      * MessyGroup is a special face group containing faces that cannot find any
      similar counterpart

      face from original faces. The messyGroup will not appear in the result if
      all faces found their

      counterparts.

      * Group API needs at least 2 candidate faces and 1000 at most. We suggest
      to try [Face -

      Verify](https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface)
      when you only have 2

      candidate faces.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be the same.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: 'function group(faceIds: string[], options?: msRest.RequestOptionsBase)'
      parameters:
        - id: faceIds
          type: 'string[]'
          description: >-
            Array of candidate faceId created by Face - Detect. The maximum is
            1000 faces
        - id: options
          type: <xref uid="msRest.RequestOptionsBase" />
          description: ''
      return:
        type: Promise&lt;<xref uid="Models.FaceGroupResponse" />&gt;
        description: Promise<Models.FaceGroupResponse>
  - name: 'group(string[], RequestOptionsBase, ServiceCallback<GroupResult>)'
    uid: '@azure/cognitiveservices-face.Face.group_2'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function group(faceIds: string[], options: RequestOptionsBase, callback:
        ServiceCallback<GroupResult>)
      parameters:
        - id: faceIds
          type: 'string[]'
          description: >-
            Array of candidate faceId created by Face - Detect. The maximum is
            1000 faces
        - id: options
          type: RequestOptionsBase
          description: The optional parameters
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.GroupResult" />&gt;
          description: |
            The callback
  - name: 'group(string[], ServiceCallback<GroupResult>)'
    uid: '@azure/cognitiveservices-face.Face.group_1'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function group(faceIds: string[], callback:
        ServiceCallback<GroupResult>)
      parameters:
        - id: faceIds
          type: 'string[]'
          description: >-
            Array of candidate faceId created by Face - Detect. The maximum is
            1000 faces
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.GroupResult" />&gt;
          description: |
            The callback
  - name: >-
      identify(string[], FaceIdentifyOptionalParams,
      ServiceCallback<IdentifyResult[]>)
    uid: '@azure/cognitiveservices-face.Face.identify_2'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function identify(faceIds: string[], options:
        FaceIdentifyOptionalParams, callback: ServiceCallback<IdentifyResult[]>)
      parameters:
        - id: faceIds
          type: 'string[]'
          description: >-
            Array of query faces faceIds, created by the Face - Detect. Each of
            the faces are

            identified independently. The valid number of faceIds is between [1,
            10].
        - id: options
          type: >-
            <xref uid="@azure/cognitiveservices-face.FaceIdentifyOptionalParams"
            />
          description: The optional parameters
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.IdentifyResult" />[]&gt;
          description: |
            The callback
  - name: 'identify(string[], Models.FaceIdentifyOptionalParams)'
    uid: '@azure/cognitiveservices-face.Face.identify'
    package: '@azure/cognitiveservices-face'
    summary: >-
      1-to-many identification to find the closest matches of the specific query
      person face from a

      person group or large person group.

      <br/> For each face in the faceIds array, Face Identify will compute
      similarities between the

      query face and all the faces in the person group (given by personGroupId)
      or large person group

      (given by largePersonGroupId), and return candidate person(s) for that
      face ranked by similarity

      confidence. The person group/large person group should be trained to make
      it ready for

      identification. See more in [PersonGroup -

      Train](https://docs.microsoft.com/rest/api/faceapi/persongroup/train) and
      [LargePersonGroup -

      Train](https://docs.microsoft.com/rest/api/faceapi/largepersongroup/train).

      <br/>

      Remarks:<br />

      * The algorithm allows more than one face to be identified independently
      at the same request,

      but no more than 10 faces.

      * Each person in the person group/large person group could have more than
      one face, but no more

      than 248 faces.

      * Higher face image quality means better identification precision. Please
      consider high-quality

      faces: frontal, clear, and face size is 200x200 pixels (100 pixels between
      eyes) or bigger.

      * Number of candidates returned is restricted by
      maxNumOfCandidatesReturned and

      confidenceThreshold. If no person is identified, the returned candidates
      will be an empty array.

      * Try [Face - Find
      Similar](https://docs.microsoft.com/rest/api/faceapi/face/findsimilar)
      when

      you need to find similar faces from a face list/large face list instead of
      a person group/large

      person group.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be the same as the

      'recognitionModel' used by the target person group or large person group.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function identify(faceIds: string[], options?:
        Models.FaceIdentifyOptionalParams)
      parameters:
        - id: faceIds
          type: 'string[]'
          description: >-
            Array of query faces faceIds, created by the Face - Detect. Each of
            the faces are

            identified independently. The valid number of faceIds is between [1,
            10].
        - id: options
          type: <xref uid="Models.FaceIdentifyOptionalParams" />
          description: ''
      return:
        type: Promise&lt;<xref uid="Models.FaceIdentifyResponse" />&gt;
        description: Promise<Models.FaceIdentifyResponse>
  - name: 'identify(string[], ServiceCallback<IdentifyResult[]>)'
    uid: '@azure/cognitiveservices-face.Face.identify_1'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function identify(faceIds: string[], callback:
        ServiceCallback<IdentifyResult[]>)
      parameters:
        - id: faceIds
          type: 'string[]'
          description: >-
            Array of query faces faceIds, created by the Face - Detect. Each of
            the faces are

            identified independently. The valid number of faceIds is between [1,
            10].
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.IdentifyResult" />[]&gt;
          description: |
            The callback
  - name: 'verifyFaceToFace(string, string, msRest.RequestOptionsBase)'
    uid: '@azure/cognitiveservices-face.Face.verifyFaceToFace'
    package: '@azure/cognitiveservices-face'
    summary: >-
      Verify whether two faces belong to a same person or whether one face
      belongs to a person.

      <br/>

      Remarks:<br />

      * Higher face image quality means better identification precision. Please
      consider high-quality

      faces: frontal, clear, and face size is 200x200 pixels (100 pixels between
      eyes) or bigger.

      * For the scenarios that are sensitive to accuracy please make your own
      judgment.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be the same as the

      'recognitionModel' used by the target face, person group or large person
      group.
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function verifyFaceToFace(faceId1: string, faceId2: string, options?:
        msRest.RequestOptionsBase)
      parameters:
        - id: faceId1
          type: string
          description: 'FaceId of the first face, comes from Face - Detect'
        - id: faceId2
          type: string
          description: 'FaceId of the second face, comes from Face - Detect'
        - id: options
          type: <xref uid="msRest.RequestOptionsBase" />
          description: ''
      return:
        type: Promise&lt;<xref uid="Models.FaceVerifyFaceToFaceResponse" />&gt;
        description: Promise<Models.FaceVerifyFaceToFaceResponse>
  - name: >-
      verifyFaceToFace(string, string, RequestOptionsBase,
      ServiceCallback<VerifyResult>)
    uid: '@azure/cognitiveservices-face.Face.verifyFaceToFace_2'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function verifyFaceToFace(faceId1: string, faceId2: string, options:
        RequestOptionsBase, callback: ServiceCallback<VerifyResult>)
      parameters:
        - id: faceId1
          type: string
          description: 'FaceId of the first face, comes from Face - Detect'
        - id: faceId2
          type: string
          description: 'FaceId of the second face, comes from Face - Detect'
        - id: options
          type: RequestOptionsBase
          description: The optional parameters
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.VerifyResult" />&gt;
          description: |
            The callback
  - name: 'verifyFaceToFace(string, string, ServiceCallback<VerifyResult>)'
    uid: '@azure/cognitiveservices-face.Face.verifyFaceToFace_1'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function verifyFaceToFace(faceId1: string, faceId2: string, callback:
        ServiceCallback<VerifyResult>)
      parameters:
        - id: faceId1
          type: string
          description: 'FaceId of the first face, comes from Face - Detect'
        - id: faceId2
          type: string
          description: 'FaceId of the second face, comes from Face - Detect'
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.VerifyResult" />&gt;
          description: |
            The callback
  - name: >-
      verifyFaceToPerson(string, string, FaceVerifyFaceToPersonOptionalParams,
      ServiceCallback<VerifyResult>)
    uid: '@azure/cognitiveservices-face.Face.verifyFaceToPerson_2'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function verifyFaceToPerson(faceId: string, personId: string, options:
        FaceVerifyFaceToPersonOptionalParams, callback:
        ServiceCallback<VerifyResult>)
      parameters:
        - id: faceId
          type: string
          description: 'FaceId of the face, comes from Face - Detect'
        - id: personId
          type: string
          description: >-
            Specify a certain person in a person group or a large person group.
            personId is

            created in PersonGroup Person - Create or LargePersonGroup Person -
            Create.
        - id: options
          type: >-
            <xref
            uid="@azure/cognitiveservices-face.FaceVerifyFaceToPersonOptionalParams"
            />
          description: The optional parameters
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.VerifyResult" />&gt;
          description: |
            The callback
  - name: >-
      verifyFaceToPerson(string, string,
      Models.FaceVerifyFaceToPersonOptionalParams)
    uid: '@azure/cognitiveservices-face.Face.verifyFaceToPerson'
    package: '@azure/cognitiveservices-face'
    summary: >-
      Verify whether two faces belong to a same person. Compares a face Id with
      a Person Id
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function verifyFaceToPerson(faceId: string, personId: string, options?:
        Models.FaceVerifyFaceToPersonOptionalParams)
      parameters:
        - id: faceId
          type: string
          description: 'FaceId of the face, comes from Face - Detect'
        - id: personId
          type: string
          description: >-
            Specify a certain person in a person group or a large person group.
            personId is

            created in PersonGroup Person - Create or LargePersonGroup Person -
            Create.
        - id: options
          type: <xref uid="Models.FaceVerifyFaceToPersonOptionalParams" />
          description: ''
      return:
        type: Promise&lt;<xref uid="Models.FaceVerifyFaceToPersonResponse" />&gt;
        description: Promise<Models.FaceVerifyFaceToPersonResponse>
  - name: 'verifyFaceToPerson(string, string, ServiceCallback<VerifyResult>)'
    uid: '@azure/cognitiveservices-face.Face.verifyFaceToPerson_1'
    package: '@azure/cognitiveservices-face'
    summary: ''
    remarks: ''
    isPreview: false
    isDeprecated: false
    syntax:
      content: >-
        function verifyFaceToPerson(faceId: string, personId: string, callback:
        ServiceCallback<VerifyResult>)
      parameters:
        - id: faceId
          type: string
          description: 'FaceId of the face, comes from Face - Detect'
        - id: personId
          type: string
          description: >-
            Specify a certain person in a person group or a large person group.
            personId is

            created in PersonGroup Person - Create or LargePersonGroup Person -
            Create.
        - id: callback
          type: >-
            ServiceCallback&lt;<xref
            uid="@azure/cognitiveservices-face.VerifyResult" />&gt;
          description: |
            The callback
